{
    "problem-profiles--artificial-intelligence:0000": "# Предотвращение катастрофы, связанной с ИИ\n## ИИ может принести человечеству очень много пользы. Если мы избежим рисков\n<p class=\"entry-meta small\">By <span class=\"byline author vcard\"><a href=\"https://80000hours.org/author/benjamin-hilton/\" rel=\"author\" class=\"fn no-visited-styling\">Бенджамен Хилтон</a></span> · Опубликовано в августе 2022</p>",
    "problem-profiles--artificial-intelligence:0004": "<div class=\"problem-profile__introduction margin-top\"><div class=\"problem-profile-introduction\">",
    "problem-profiles--artificial-intelligence:0006": "##~class=\"no_toc\"~",
    "problem-profiles--artificial-intelligence:0008": "<div class=\"margin-bottom margin-top\" id=\"audio-player\"><div class=\"wrap-smart-track-player\"><div class=\"smart-track-player-container stp-color-60b86c-2a2e30\">\n</div></div></div>",
    "problem-profiles--artificial-intelligence:0011": "Почему судьбу мира определяют люди, а не шимпанзе?",
    "problem-profiles--artificial-intelligence:0013": "Люди решают, как будет выглядеть каждый уголок нашей планеты. Шимпанзе, конечно, очень умные по сравнению с другими животными, но им такая власть недоступна.",
    "problem-profiles--artificial-intelligence:0015": "(В общих чертах) такое положение дел вызвано интеллектом людей.[^:`Что мы подразумеваем здесь под \"интеллектом\"? Что-то вроде \"способности влиять на будущее предсказуемым образом\". Эта способность включает в себя понимание мира, достаточное для того, чтобы строить планы, которые будут работать, и способность претворять эти планы в жизнь. То, что люди способны влиять на будущее предсказуемым образом, означает, что они могут изменять мир вокруг себя, чтобы достигать своих целей и удовлетворять свои потребности. Важность способности строить и реализовывать планы мы более подробно обсудим [далее](#aps-systems).`]",
    "problem-profiles--artificial-intelligence:0017": "Компании и правительства тратят на разработку ИИ-систем [миллиарды долларов в год](https://web.archive.org/web/20221013005552/https://aiimpacts.org/funding-of-ai-research/). Когда эти системы станут достаточно продвинутыми, люди (рано или поздно) могут перестать быть самыми разумными существами на планете. [Как мы увидим](#making-advances-extremely-quickly), ИИ-системы развиваются. И быстро.",
    "problem-profiles--artificial-intelligence:0019": "Сколько именно времени займёт создание искусственного интеллекта, который будет справляться с подавляющим большинством задач лучше человека, — [предмет крайне оживлённых дискуссий](#when-can-we-expect-to-develop-transformative-AI). Но, судя по всему, появление такого ИИ возможно, и мы предполагаем, что оно случится в этом веке.",
    "problem-profiles--artificial-intelligence:0021": "Само по себе утверждение, что в этом веке искусственный интеллект превзойдёт человеческий, не влечёт за собой автоматически вывода, что искусственный интеллект — это очень важно или что он представляет собой угрозу для человечества. Ниже мы рассмотрим эти утверждения гораздо более подробно.",
    "problem-profiles--artificial-intelligence:0023": "Однако, судя по всему, вполне можно сказать, что потенциальное появление на Земле в ближайшем будущем интеллекта, соперничающего с человеческим, — это как минимум повод задуматься.",
    "problem-profiles--artificial-intelligence:0025": "Будут ли цели у систем, которые мы разрабатываем? И если да, то что это будут за цели?",
    "problem-profiles--artificial-intelligence:0027": "Будут ли они помогать человечеству в его стремлении творить добро? Или мы перестанем управлять нашим будущем и фактически история человечества на этом завершится?",
    "problem-profiles--artificial-intelligence:0029": "Честный ответ на эти вопросы: мы не знаем.",
    "problem-profiles--artificial-intelligence:0031": "Однако мы не можем просто ждать, скрестив пальцы, и беспристрастно наблюдать. Искусственный интеллект действительно может радикально изменить всё. Поэтому работа над тем, как он будет развиваться, — возможно, самое значимое, что мы можем делать.",
    "problem-profiles--artificial-intelligence:0033": "</div>",
    "problem-profiles--artificial-intelligence:0035": "<div class=\"problem-profile__summary panel margin-top\">",
    "problem-profiles--artificial-intelligence:0037": "## Краткое изложение",
    "problem-profiles--artificial-intelligence:0039": "Мы ожидаем, что в ближайшие десятилетия будет достигнут значительный прогресс в области искусственного интеллекта: возможно, машины даже превзойдут людей во многих — а возможно, даже во всех — задачах. Это может принести гигантскую пользу — например, поможет справиться с глобальными проблемами, которые сейчас неразрешимы, но также несёт в себе серьёзные риски. Эти риски могут породить опасные последствия как случайно (например, если мы не сможем решить задачу безопасности систем ИИ) или в результате человеческих решений (например, если системы ИИ ухудшат геополитический конфликт). Мы считаем, что для уменьшения этих рисков нужно сделать многое.",
    "problem-profiles--artificial-intelligence:0041": "Некоторые из рисков, которые несут в себе продвинутые ИИ, могут оказаться [экзистенциальными](/articles/existential-risks/) — то есть, они могут привести к исчезновению человечества или к тому, что человечество навсегда потеряет возможность управлять собственной судьбой.[^:`Также нас беспокоит вопрос о том, что системы ИИ, возможно, тоже следует учитывать с точки зрения этики — например, потому что они разумны. В этой статье мы не будем обсуждать этот вопрос, ему посвящена [отдельная статья](/problem-profiles/artificial-sentience/).`] Ниже обсуждаются важные вопросы о том, насколько так стремительно развивающаяся революционная технология может быть разработана безопасным образом и как она встроится в наше общество. Удовлетворительных ответов на эти вопросы пока нет, а задача поиска этих ответов крайне недооценена, но может быть разрешима. По нашим оценкам напрямую этим занимаются примерно 400 человек в мире.[^:`Количество таких людей оценить сложно.",
    "problem-profiles--artificial-intelligence:0043": "В идеале мы хотим оценить, сколько на задачу снижения экзистенциальных рисков от ИИ тратится ЭПЗ (\" [эквивалентов полной занятости](https://en.wikipedia.org/wiki/Full-time_equivalent)\").",
    "problem-profiles--artificial-intelligence:0045": "Однако в вопросе, кого считать работающим над этой задачей, есть множество неоднозначностей. Поэтому для своих оценок я пользовался следующими правилами:",
    "problem-profiles--artificial-intelligence:0047": "- Я не включал людей, которые, хотя, возможно, и предполагают, что они готовятся работать над предотвращением катастрофы, связанной с ИИ, но которые в настоящее время лишь учатся, а не работают над задачей напрямую.\n- Я включал исследователей, инженеров и прочий персонал, которые, судя по всему, напрямую занимаются исследованиями в области безопасности ИИ или вопросами регулирования ИИ и разработкой стратегий. Однако граница между этими людьми и теми, кого я решил не включать, довольно нечёткая. Например, я не включал специалистов по машинному обучению, разрабатывающих системы ИИ, которые потенциально можно использовать для исследований безопасности, но которые не разрабатывались в первую очередь именно для этой цели.\n- Я учитывал лишь время, потраченное на задачу снижения потенциальных [экзистенциальных рисков](/articles/existential-risks/) от ИИ, вроде тех, что обсуждаются в этой статье. Множество работ по безопасности и этике ИИ рассматривают более общие вопросы, а также другие риски, связанные с ИИ. Такие работы могут помогать снижению экзистенциальных рисков, и это усложняет подсчёты. Я решил учитывать только работы, которые напрямую связаны со снижением рисков от катастрофы, связанной с ИИ (подробнее читайте в [разделе, посвящённом нашей модели для оценки проблем](/articles/problem-framework/#a-challenge-direct-vs-indirect-future-effort)).\n- Аналогично я не учитывал людей, работающих над задачами, которые могут косвенно влиять на шансы катастрофы, связанной с ИИ: например, [улучшением эпистемологии и принятия решений в организациях]((/problem-profiles/improving-institutional-decision-making/), снижением вероятности [конфликта сверхдержав]((/problem-profiles/great-power-conflict/) или [распространением идей эффективного альтруизма](/problem-profiles/promoting-effective-altruism/).",
    "problem-profiles--artificial-intelligence:0052": "Определившись с этими правилами, я оценил количество ЭПЗ тремя способами.",
    "problem-profiles--artificial-intelligence:0054": "Во-первых, я оценил количество ЭПЗ, работающих напрямую над задачей снижения экзистенциальных рисков от ИИ, в каждой из организаций из базы данных [AI Watch](https://aiwatch.issarice.com/). Для этого я посмотрел, сколько в каждой из организаций числилось персонала — как всего, так и отдельно в 2022 году, — а также сколько в каждой из организаций числилось исследователей. В итоге я оценил количество людей, занимающихся техническими вопросами безопасности ИИ, в 76 — 536 ЭПЗ (90% доверительный интервал) при матожидании 196 ЭПЗ. Количество людей, занимающихся вопросами регулирования ИИ и разработкой стратегий, я оценил в 51 — 239 ЭПЗ (90% доверительный интервал) при матожидании в 151 ЭПЗ. Из-за неоднозначностей, описанных выше, на эти оценки значительно влияет субъективный фактор. Мои оценки могут оказаться сильно занижены, если в базе AI Watch отсутствуют данные по каким-то организациям, или значительно завышены, если данные учитывают каких-то людей несколько раз или включают людей, которые больше не занимаются упомянутыми задачами.",
    "problem-profiles--artificial-intelligence:0056": "Во-вторых, я взял методику, которой пользовался [Гэвин Лич для оценки количества людей, работающих над снижением экзистенциальных рисков от ИИ](https://forum.effectivealtruism.org/posts/8ErtxW7FRPGMtDqJy/the-academic-contribution-to-ai-safety-seems-large), и немного её доработал. Я разделил организации в оценках Лича на технические вопросы безопасности и регулирование/стратегии. Также я адаптировал числа Гэвина для доли научных работ в области информатики, которые относятся к теме безопасности ИИ и удовлетворяют ограничениям выше, и сделал соответствующие оценки для научных работ, которые не относятся к информатике, но относятся к нашей теме. В итоге у меня получилась оценка в 125 —1848 ЭПЗ (90% доверительный интервал) при матожидании 580 ЭПЗ для людей, которые занимаются техническими вопросами безопасности ИИ и 48 — 268 ЭПЗ (90% доверительный интервал) при матожидании 100 ЭПЗ для людей, которые занимаются регулированием и стратегиями.",
    "problem-profiles--artificial-intelligence:0058": "В-третьих, я посмотрел на оценки аналогичных чисел, сделанные [Стивеном МакЭлисом](https://forum.effectivealtruism.org/posts/3gmkrj3khJHndYGNe/estimating-the-current-and-future-number-of-ai-safety). В его подсчётах я немного по-другому распределил организации по категориям, чтобы результаты соответствовали предыдущим двум оценкам. В итоге у меня получилось 110 — 552 ЭПЗ (90% доверительный интервал) при матожидании 267 ЭПЗ для людей, которые работают над техническими вопросами безопасности ИИ, и 36 — 193 ЭПЗ (90% доверительный интервал) при матожидании 81 ЭПЗ для людей, которые занимаются регулированием и стратегиями.",
    "problem-profiles--artificial-intelligence:0060": "Для итоговой оценки я взял геометрическое среднее от полученных результатов и объединил доверительные интервалы в предположении, что распределение здесь приблизительно логнормальное.",
    "problem-profiles--artificial-intelligence:0062": "Наконец я оценил количество ЭПЗ для [вспомогательного персонала](#complementary-yet-crucial-roles) на основании базы данных AI Watch. Из релевантных организаций я выбрал те, для которых было достаточно данных о количестве исследователей. Затем я посчитал соотношения между числом исследователей в 2022 году и общим числом сотрудников в 2022 году в этих организациях, и для этих соотношений посчитал матожидание и доверительный интервал (исходя из дисперсии). Эти результаты я использовал, чтобы посчитать общее число вспомогательного персонала, исходя из предположения, что количество сотрудников распределено логнормально, а оценка упомянутых соотношений — нормально. В итоге у меня получилось 2 — 2357 ЭПЗ (90% доверительный интервал) с матожиданием 770 ЭПЗ для вспомогательного персонала.",
    "problem-profiles--artificial-intelligence:0064": "Вероятно, в этой методике много ошибок, однако я ожидаю, что эти ошибки малы по сравнению с неопределённостью в исходных данных, которые я использовал. По \n\nНЕЗАКОНЧЕНО.",
    "problem-profiles--artificial-intelligence:0080": "<div class=\"margin-top\">",
    "problem-profiles--artificial-intelligence:0084": "<div>",
    "problem-profiles--artificial-intelligence:0127": "</div></div>",
    "problem-profiles--artificial-intelligence:0129": "<div class=\"margin-top\">",
    "problem-profiles--artificial-intelligence:0133": "<div>",
    "problem-profiles--artificial-intelligence:0137": "</div></div></div></div>",
    "problem-profiles--artificial-intelligence:0141": "<div class=\"no-print well margin-top\">",
    "problem-profiles--artificial-intelligence:0145": "</div></div>",
    "problem-profiles--artificial-intelligence:0147": "<div class=\"problem-profile-content padding-bottom-large\">\n!toc-container",
    "problem-profiles--artificial-intelligence:0150": "<div class=\"well bg-gray-lighter margin-bottom margin-top padding-top-small padding-bottom-small\">",
    "problem-profiles--artificial-intelligence:0162": "</div>",
    "problem-profiles--artificial-intelligence:0305": "<a id=\"what-is-deep-learning\" class=\"link-anchor\"></a>",
    "problem-profiles--artificial-intelligence:0325": "</aside>",
    "problem-profiles--artificial-intelligence:0400": "<a id=\"GPT-3\" class=\"link-anchor\"></a>",
    "problem-profiles--artificial-intelligence:0433": "</aside>",
    "problem-profiles--artificial-intelligence:0478": "<div class=\"container--page-width\"><div class=\"row\"><div class=\"tablepress-scroll-wrapper\" id=\"tablepress-189-no-2-scroll-wrapper\">",
    "problem-profiles--artificial-intelligence:0487": "</div></div></div>",
    "problem-profiles--artificial-intelligence:0611": "</div>",
    "problem-profiles--artificial-intelligence:0613": "<div class=\"panel-body-collapse collapse\" id=\"-20\"><div class=\"panel-body\">",
    "problem-profiles--artificial-intelligence:0621": "</div></div></div>",
    "problem-profiles--artificial-intelligence:0626": "</div>",
    "problem-profiles--artificial-intelligence:0628": "<div class=\"panel-body-collapse collapse\" id=\"-21\"><div class=\"panel-body\">",
    "problem-profiles--artificial-intelligence:0636": "</div></div></div>",
    "problem-profiles--artificial-intelligence:0641": "</div>",
    "problem-profiles--artificial-intelligence:0643": "<div class=\"panel-body-collapse collapse\" id=\"-22\"><div class=\"panel-body\">",
    "problem-profiles--artificial-intelligence:0653": "</div></div></div></div></div>",
    "problem-profiles--artificial-intelligence:0724": "<div class=\"well bg-gray-lighter margin-bottom margin-top padding-top-small padding-bottom-small\">",
    "problem-profiles--artificial-intelligence:0735": "</div>",
    "problem-profiles--artificial-intelligence:0776": "<div class=\"panel clearfix \">",
    "problem-profiles--artificial-intelligence:0786": "</div>",
    "problem-profiles--artificial-intelligence:0941": "</div>",
    "problem-profiles--artificial-intelligence:1003": "</div>",
    "problem-profiles--artificial-intelligence:1005": "<div class=\"panel-body-collapse collapse\" id=\"-23\"><div class=\"panel-body\">",
    "problem-profiles--artificial-intelligence:1019": "</div></div></div>",
    "problem-profiles--artificial-intelligence:1024": "</div>",
    "problem-profiles--artificial-intelligence:1026": "<div class=\"panel-body-collapse collapse\" id=\"-24\"><div class=\"panel-body\">",
    "problem-profiles--artificial-intelligence:1038": "</div></div></div>",
    "problem-profiles--artificial-intelligence:1043": "</div>",
    "problem-profiles--artificial-intelligence:1045": "<div class=\"panel-body-collapse collapse\" id=\"-25\"><div class=\"panel-body\">",
    "problem-profiles--artificial-intelligence:1060": "</div></div></div>",
    "problem-profiles--artificial-intelligence:1065": "</div>",
    "problem-profiles--artificial-intelligence:1067": "<div class=\"panel-body-collapse collapse\" id=\"-26\"><div class=\"panel-body\">",
    "problem-profiles--artificial-intelligence:1111": "</div></div></div></div>",
    "problem-profiles--artificial-intelligence:1120": "</div>",
    "problem-profiles--artificial-intelligence:1122": "<div class=\"panel-body-collapse collapse\" id=\"-28\"><div class=\"panel-body\">",
    "problem-profiles--artificial-intelligence:1138": "</div></div></div>",
    "problem-profiles--artificial-intelligence:1143": "</div>",
    "problem-profiles--artificial-intelligence:1145": "<div class=\"panel-body-collapse collapse\" id=\"-29\"><div class=\"panel-body\">",
    "problem-profiles--artificial-intelligence:1168": "</div>",
    "problem-profiles--artificial-intelligence:1170": "<div class=\"panel-body-collapse collapse\" id=\"-30\"><div class=\"panel-body\">",
    "problem-profiles--artificial-intelligence:1187": "</div></div></div>",
    "problem-profiles--artificial-intelligence:1192": "</div>",
    "problem-profiles--artificial-intelligence:1194": "<div class=\"panel-body-collapse collapse\" id=\"-31\"><div class=\"panel-body\">",
    "problem-profiles--artificial-intelligence:1211": "</div>",
    "problem-profiles--artificial-intelligence:1213": "<div class=\"panel-body-collapse collapse\" id=\"-32\"><div class=\"panel-body\">"
}
